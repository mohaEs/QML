{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26rZ4SxdrWeI"
   },
   "source": [
    "## This notebook presents the reproducible procedure that we followed in comparing the performance of Hybrid Quantum Neural Networks-Parallel and Classical Convolutional Neural Networks on the IDRID dataset. The IDRID dataset is a diabetic-retinopathy dataset with 516 fundus images. The dataset was produced in India and is labeled with five-category classification (no diabetic retinopathy, mild diabetic retinopathy, moderate diabetic retinopathy, severe diabetic retinopathy, and proliferative diabetic retinopathy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i0eTf0VqdT9"
   },
   "source": [
    "### Installing and Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-MaCMIv5mjj",
    "outputId": "28220fa0-11ae-45ba-8178-518dcfc9fb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (0.38.0)\n",
      "Requirement already satisfied: numpy<2.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (3.2.1)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (0.16.0)\n",
      "Requirement already satisfied: autograd in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (1.8.0)\n",
      "Requirement already satisfied: toml in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: appdirs in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: autoray>=0.6.11 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (0.7.1)\n",
      "Requirement already satisfied: cachetools in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (5.5.2)\n",
      "Requirement already satisfied: pennylane-lightning>=0.38 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (0.38.0)\n",
      "Requirement already satisfied: requests in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (4.13.2)\n",
      "Requirement already satisfied: packaging in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pennylane) (25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from requests->pennylane) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from requests->pennylane) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from requests->pennylane) (2025.4.26)\n",
      "Requirement already satisfied: matplotlib in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: opencv-python in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: seaborn in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from seaborn) (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/eslamim/miniconda3/envs/env_QML/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install scikit-learn\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QydOZT6j5sRX"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#from google.colab import drive\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve,\n",
    "    precision_recall_curve, auc, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import random\n",
    "from itertools import cycle\n",
    "\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EF-9MvDrE2Dn",
    "outputId": "23c0032b-2d9b-4b49-9b91-1838954b9464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkRe0rr15zDM",
    "outputId": "ae5aae44-f296-4eca-f6ef-413715af87d0"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g3_l3J878S7p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../../QMLExperiments/IDRID_models_QNN-Parallel/' created.\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = \"../../QMLExperiments/IDRID_models_QNN-Parallel/\"\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.makedirs(MODEL_SAVE_PATH)\n",
    "    print(f\"Directory '{MODEL_SAVE_PATH}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJQuUMZ-q6IA"
   },
   "source": [
    "### General Training, Validation, Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SugqsjmzoHZ5"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "02QPbTDTovSw"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    accuracy = correct / total * 100\n",
    "\n",
    "    aurocs = []\n",
    "    for i in range(probs.shape[1]):\n",
    "        try:\n",
    "            auroc = roc_auc_score([1 if label == i else 0 for label in all_labels], [prob[i] for prob in all_probs])\n",
    "            aurocs.append(auroc)\n",
    "        except ValueError:\n",
    "            aurocs.append(0)\n",
    "\n",
    "    avg_auroc = sum(aurocs) / len(aurocs)\n",
    "\n",
    "    return avg_train_loss, accuracy, avg_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5eTduRxKox8S"
   },
   "outputs": [],
   "source": [
    "def validate_model(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_loader.dataset)\n",
    "    accuracy = correct / total * 100\n",
    "    aurocs = []\n",
    "    for i in range(probs.shape[1]):\n",
    "        try:\n",
    "            auroc = roc_auc_score([1 if label == i else 0 for label in all_labels], [prob[i] for prob in all_probs])\n",
    "            aurocs.append(auroc)\n",
    "        except ValueError:\n",
    "            aurocs.append(0)\n",
    "\n",
    "    avg_auroc = sum(aurocs) / len(aurocs)\n",
    "\n",
    "    return avg_val_loss, accuracy, avg_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jyvWgmeMoU6-"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def train_validate_model(n_epochs, model, model_name, train_loader, valid_loader, seed, quantum=False):\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "  def adjust_learning_rate(optimizer, epoch, lr_warmup_epochs, lr_max):\n",
    "        if epoch < lr_warmup_epochs:\n",
    "            lr = lr_max * (epoch + 1) / lr_warmup_epochs\n",
    "        else:\n",
    "            lr = lr_max\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "  scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs - 10, eta_min=1e-6)\n",
    "\n",
    "  best_val_loss = float('inf')\n",
    "  best_model_weights = model.state_dict()\n",
    "  epochs_without_improvement = 0\n",
    "  early_stopping_patience = 10\n",
    "\n",
    "  train_losses = []\n",
    "  train_accuracies = []\n",
    "  val_losses = []\n",
    "  val_accuracies = []\n",
    "  train_aucs = []\n",
    "  val_aucs = []\n",
    "\n",
    "  lr_max = 5e-4\n",
    "  lr_warmup_epochs = 10\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "      print(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "\n",
    "      adjust_learning_rate(optimizer, epoch, lr_warmup_epochs, lr_max)\n",
    "\n",
    "      train_loss, train_accuracy, train_auroc = train_model(model, train_loader, optimizer, criterion)\n",
    "      val_loss, val_accuracy, val_auroc = validate_model(model, valid_loader, criterion)\n",
    "\n",
    "\n",
    "      print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Training AUROC: {train_auroc:.4f}')\n",
    "      print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Validation AUROC: {val_auroc:.4f}')\n",
    "      train_losses.append(train_loss)\n",
    "      train_accuracies.append(train_accuracy)\n",
    "      train_aucs.append(train_auroc)\n",
    "      val_losses.append(val_loss)\n",
    "      val_accuracies.append(val_accuracy)\n",
    "      val_aucs.append(val_auroc)\n",
    "\n",
    "      if epoch >= lr_warmup_epochs:\n",
    "            scheduler.step()\n",
    "\n",
    "      if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict()\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "\n",
    "      else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "      if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "  model.load_state_dict(best_model_weights)\n",
    "\n",
    "  if quantum:\n",
    "    torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, f'{model_name}_{seed}.pth'))\n",
    "  else:\n",
    "    torch.save(model, os.path.join(MODEL_SAVE_PATH, f'{model_name}_{seed}.pth'))\n",
    "\n",
    "  metrics = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accuracies\": train_accuracies,\n",
    "        \"train_aucs\": train_aucs,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"val_accuracies\": val_accuracies,\n",
    "        \"val_aucs\": val_aucs\n",
    "    }\n",
    "\n",
    "  with open(os.path.join(MODEL_SAVE_PATH, f'{model_name}_{seed}_metrics.pkl'), 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "\n",
    "  return model, train_losses, train_accuracies, val_losses, val_accuracies, train_aucs, val_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RBPOU7w_oZmN"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(quantum_loss, normal_loss, quantum_acc, normal_acc, quantum_auc, normal_auc):\n",
    "    plt.style.use(\"default\")\n",
    "\n",
    "    loss_min = math.floor(min(min(quantum_loss), min(normal_loss)) * 10) / 10\n",
    "    loss_max = math.ceil(max(max(quantum_loss), max(normal_loss)) * 10) / 10\n",
    "\n",
    "    acc_min = math.floor(min(min(quantum_acc), min(normal_acc)) * 10) / 10\n",
    "    acc_max = math.ceil(max(max(quantum_acc), max(normal_acc)) * 10) / 10\n",
    "\n",
    "    auc_min = math.floor(min(min(quantum_auc), min(normal_auc)) * 10) / 10\n",
    "    auc_max = math.ceil(max(max(quantum_auc), max(normal_auc)) * 10) / 10\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(quantum_loss, label=\"With quantum layer\")\n",
    "    plt.plot(normal_loss, label=\"Without quantum layer\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.ylim([loss_min, loss_max])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss vs. Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(quantum_acc, label=\"With quantum layer\")\n",
    "    plt.plot(normal_acc, label=\"Without quantum layer\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim([acc_min, acc_max])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy vs. Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(quantum_auc, label=\"With quantum layer\")\n",
    "    plt.plot(normal_auc, label=\"Without quantum layer\")\n",
    "    plt.ylabel(\"ROCAUC\")\n",
    "    plt.ylim([auc_min, auc_max])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.title(\"ROCAUC vs. Epoch\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0c9fAaL6lPqw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def test(model_hybrid, model_normal, test_loader, num_classes):\n",
    "    model_hybrid.eval()\n",
    "    model_normal.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds_hybrid = []\n",
    "    all_preds_normal = []\n",
    "    all_probs_hybrid = []\n",
    "    all_probs_normal = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            outputs_hybrid = model_hybrid(images)\n",
    "            _, preds_hybrid = torch.max(outputs_hybrid, 1)\n",
    "            probs_hybrid = torch.softmax(outputs_hybrid, dim=1)\n",
    "            # Normal model predictions\n",
    "            outputs_normal = model_normal(images)\n",
    "            _, preds_normal = torch.max(outputs_normal, 1)\n",
    "            probs_normal = torch.softmax(outputs_normal, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds_hybrid.extend(preds_hybrid.cpu().numpy())\n",
    "            all_preds_normal.extend(preds_normal.cpu().numpy())\n",
    "            all_probs_hybrid.extend(probs_hybrid.cpu().numpy())\n",
    "            all_probs_normal.extend(probs_normal.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds_hybrid = np.array(all_preds_hybrid)\n",
    "    all_preds_normal = np.array(all_preds_normal)\n",
    "    all_probs_hybrid = np.array(all_probs_hybrid)\n",
    "    all_probs_normal = np.array(all_probs_normal)\n",
    "\n",
    "\n",
    "    accuracy_hybrid = accuracy_score(all_labels, all_preds_hybrid)\n",
    "    accuracy_normal = accuracy_score(all_labels, all_preds_normal)\n",
    "\n",
    "\n",
    "    f1_hybrid = f1_score(all_labels, all_preds_hybrid, average='weighted')\n",
    "    f1_normal = f1_score(all_labels, all_preds_normal, average='weighted')\n",
    "\n",
    "\n",
    "    if num_classes == 2:\n",
    "        precision_hybrid = precision_score(all_labels, all_preds_hybrid, pos_label=1)\n",
    "        recall_hybrid = recall_score(all_labels, all_preds_hybrid, pos_label=1)\n",
    "        precision_normal = precision_score(all_labels, all_preds_normal, pos_label=1)\n",
    "        recall_normal = recall_score(all_labels, all_preds_normal, pos_label=1)\n",
    "    else:\n",
    "        precision_hybrid = precision_score(all_labels, all_preds_hybrid, average='weighted')\n",
    "        recall_hybrid = recall_score(all_labels, all_preds_hybrid, average='weighted')\n",
    "        precision_normal = precision_score(all_labels, all_preds_normal, average='weighted')\n",
    "        recall_normal = recall_score(all_labels, all_preds_normal, average='weighted')\n",
    "\n",
    "\n",
    "    hybrid_aucs = []\n",
    "    normal_aucs = []\n",
    "\n",
    "    if num_classes == 2:\n",
    "\n",
    "        all_probs_hybrid_class1 = all_probs_hybrid[:, 1]\n",
    "        all_probs_normal_class1 = all_probs_normal[:, 1]\n",
    "\n",
    "        auc_hybrid = roc_auc_score(all_labels, all_probs_hybrid_class1)\n",
    "        auc_normal = roc_auc_score(all_labels, all_probs_normal_class1)\n",
    "\n",
    "\n",
    "        fpr_hybrid, tpr_hybrid, _ = roc_curve(all_labels, all_probs_hybrid_class1)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fpr_hybrid, tpr_hybrid, label=f'Hybrid Model AUROC = {auc_hybrid:.4f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.title('ROC Curve - Hybrid Model')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot ROC curve for the Normal Model\n",
    "        fpr_normal, tpr_normal, _ = roc_curve(all_labels, all_probs_normal_class1)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fpr_normal, tpr_normal, label=f'Normal Model AUROC = {auc_normal:.4f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.title('ROC Curve - Normal Model')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        print(\"\\nHybrid Model Metrics:\")\n",
    "        print(f'Accuracy: {accuracy_hybrid:.4f}')\n",
    "        print(f'F1 Score: {f1_hybrid:.4f}')\n",
    "        print(f'Precision: {precision_hybrid:.4f}')\n",
    "        print(f'Recall: {recall_hybrid:.4f}')\n",
    "        print(f'AUROC: {auc_hybrid}')\n",
    "\n",
    "        print(\"\\nNormal Model Metrics:\")\n",
    "        print(f'Accuracy: {accuracy_normal:.4f}')\n",
    "        print(f'F1 Score: {f1_normal:.4f}')\n",
    "        print(f'Precision: {precision_normal:.4f}')\n",
    "        print(f'Recall: {recall_normal:.4f}')\n",
    "        print(f'AUROC: {auc_normal} \\n')\n",
    "\n",
    "        cm_hybrid = confusion_matrix(all_labels, all_preds_hybrid)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm_hybrid, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix: Hybrid Model (Avg AUC = {auc_hybrid})')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "\n",
    "        cm_normal = confusion_matrix(all_labels, all_preds_normal)\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm_normal, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix: Classical Model (Avg AUC = {auc_normal})')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    else:  # Multi-class Classification\n",
    "\n",
    "        all_labels_binarized = label_binarize(all_labels, classes=np.arange(num_classes))\n",
    "\n",
    "        # Define a color cycle for plotting\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "        # Plot ROC curves for the Hybrid Model\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i, color in zip(range(num_classes), colors):\n",
    "            fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_probs_hybrid[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            hybrid_aucs.append(roc_auc)\n",
    "            plt.plot(fpr, tpr, color=color, lw=2,\n",
    "                    label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Hybrid Model')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot ROC curves for the Normal Model\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i, color in zip(range(num_classes), colors):\n",
    "            fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_probs_normal[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            normal_aucs.append(roc_auc)\n",
    "            plt.plot(fpr, tpr, color=color, lw=2,\n",
    "                    label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Normal Model')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        normal_auc = f\"{sum(normal_aucs) / len(normal_aucs):.4f}\"\n",
    "        hybrid_auc = f\"{sum(hybrid_aucs) / len(hybrid_aucs):.4f}\"\n",
    "\n",
    "        print(\"\\nHybrid Model Metrics:\")\n",
    "        print(f'Accuracy: {accuracy_hybrid:.4f}')\n",
    "        print(f'F1 Score: {f1_hybrid:.4f}')\n",
    "        print(f'Precision: {precision_hybrid:.4f}')\n",
    "        print(f'Recall: {recall_hybrid:.4f}')\n",
    "        print(f'AUROC: {hybrid_auc}')\n",
    "\n",
    "        print(\"\\nNormal Model Metrics:\")\n",
    "        print(f'Accuracy: {accuracy_normal:.4f}')\n",
    "        print(f'F1 Score: {f1_normal:.4f}')\n",
    "        print(f'Precision: {precision_normal:.4f}')\n",
    "        print(f'Recall: {recall_normal:.4f}')\n",
    "        print(f'AUROC: {normal_auc} \\n')\n",
    "\n",
    "        cm_hybrid = confusion_matrix(all_labels, all_preds_hybrid)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm_hybrid, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix: Hybrid Model (Avg AUC = {hybrid_auc})')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "\n",
    "        cm_normal = confusion_matrix(all_labels, all_preds_normal)\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm_normal, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix: Classical Model (Avg AUC = {normal_auc})')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lsy4PbJwsAZk"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u_ljgobAP2a9"
   },
   "outputs": [],
   "source": [
    "def load_data(batch_size, dataset):\n",
    "\n",
    "  train_transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  ])\n",
    "\n",
    "  valid_test_transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  ])\n",
    "\n",
    "\n",
    "  if dataset == 'APTOS':\n",
    "    data_dir = \"../../Data/APTOS2019/\"\n",
    "\n",
    "  elif dataset == \"IDRID\":\n",
    "    data_dir = \"../../Data/IDRiD_data/\"\n",
    "\n",
    "  elif dataset == \"Messidor\":\n",
    "    data_dir = \"../../Data/MESSIDOR2/\"\n",
    "\n",
    "  elif dataset == \"GlaucomaFundus\":\n",
    "    data_dir = \"../../Data/Glaucoma_fundus/\"\n",
    "\n",
    "  elif dataset == \"PAPILA\":\n",
    "    data_dir = \"../../Data/PAPILA/\"\n",
    "\n",
    "  elif dataset == 'G1020':\n",
    "    data_dir = \"../../Data/G1020/\"\n",
    "\n",
    "\n",
    "  train_dataset = datasets.ImageFolder(root=data_dir + 'train', transform=train_transform)\n",
    "  val_dataset = datasets.ImageFolder(root=data_dir + 'val', transform=valid_test_transform)\n",
    "  test_dataset = datasets.ImageFolder(root=data_dir + 'test', transform=valid_test_transform)\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "  valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "  return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkUYDvkurKyc"
   },
   "source": [
    "### Classical CNN Model Construction and General Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "K69n16yn4HvW"
   },
   "outputs": [],
   "source": [
    "class NormalModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NormalModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 120)\n",
    "        self.fc2 = nn.Linear(120, 20)\n",
    "        self.fc3 = nn.Linear(20, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cqdtEdFqjNk"
   },
   "source": [
    "### Hybrid Quantum Neural Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3czKtWnSdsVY"
   },
   "outputs": [],
   "source": [
    "step = 0.0004               # Learning rate\n",
    "batch_size = 4              # Number of samples for each training step\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "start_time = time.time()    # Start of the computation timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JEdSCuIkdvFc"
   },
   "outputs": [],
   "source": [
    "n_qubits = 5\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "# Define the QLayer\n",
    "n_layers = 3\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FH1fSZLx3lLa"
   },
   "outputs": [],
   "source": [
    "class QuantumHybridModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "      super(QuantumHybridModel, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(3, 16, 5, stride=1, padding=2)\n",
    "      self.bn1 = nn.BatchNorm2d(16)\n",
    "      self.pool = nn.MaxPool2d(2, 2)\n",
    "      self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "      self.bn2 = nn.BatchNorm2d(32)\n",
    "      self.qlayer1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "      self.qlayer2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "      self.qlayer3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "      self.qlayer4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "      self.fc1 = nn.Linear(32 * 56 * 56, 120)\n",
    "      self.fc2 = nn.Linear(120, 20)\n",
    "      self.fc3 = nn.Linear(20, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagate the input through the CNN layers\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass the output to the quantum layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x_1, x_2, x_3, x_4 = torch.split(x, 5, dim=1)\n",
    "        x_1 = self.qlayer1(x_1)\n",
    "        x_2 = self.qlayer2(x_2)\n",
    "        x_3 = self.qlayer3(x_3)\n",
    "        x_4 = self.qlayer4(x_4)\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYTFRiI43dWY"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Y23p5AitonjQ"
   },
   "outputs": [],
   "source": [
    "n_epochs = 3#100\n",
    "num_classes = 5\n",
    "batch_size = 32\n",
    "dataset = \"IDRID\"\n",
    "model_name_hybrid = 'quantum_hybrid_model'\n",
    "model_name_normal = 'normal_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kk_htxIw4vmz"
   },
   "source": [
    "## Seed Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5sYLHGM_ATI",
    "outputId": "584f5cf9-2ef7-4341-c053-f0b43697705a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Seed 73:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_loader, valid_loader, test_loader \u001b[38;5;241m=\u001b[39m load_data(batch_size\u001b[38;5;241m=\u001b[39mbatch_size, dataset\u001b[38;5;241m=\u001b[39mdataset)\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m NormalModel(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdevice\u001b[49m)\n\u001b[1;32m      7\u001b[0m hybrid_model \u001b[38;5;241m=\u001b[39m QuantumHybridModel(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "seed = random.randint(1, 100)\n",
    "print(f\"Experiment with Seed {seed}:\")\n",
    "set_seed(seed)\n",
    "train_loader, valid_loader, test_loader = load_data(batch_size=batch_size, dataset=dataset)\n",
    "model = NormalModel(num_classes=5)\n",
    "hybrid_model = QuantumHybridModel(num_classes=5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "model_name_hybrid = 'quantum_hybrid_model'\n",
    "model_name_normal = 'normal_model'\n",
    "model.to(device)\n",
    "hybrid_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyx9vrtA-RvH",
    "outputId": "02151364-e31e-4338-8914-4e77bc11dadd"
   },
   "outputs": [],
   "source": [
    "model_normal, normal_train_losses, normal_train_accs, normal_val_losses, normal_val_accs, normal_train_aucs, normal_val_aucs = train_validate_model(\n",
    "    n_epochs=n_epochs,\n",
    "    model=model,\n",
    "    model_name=model_name_normal,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-rHdOBM-Nkt",
    "outputId": "595c3814-c561-4454-f2c1-76c515eff4cd"
   },
   "outputs": [],
   "source": [
    "model_hybrid, hybrid_train_losses, hybrid_train_accs, hybrid_val_losses, hybrid_val_accs, hybrid_train_aucs, hybrid_val_aucs = train_validate_model(\n",
    "    n_epochs=n_epochs,\n",
    "    model=hybrid_model,\n",
    "    model_name=model_name_hybrid,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    seed=seed,\n",
    "    quantum=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965
    },
    "id": "rYuvKUgVDMnX",
    "outputId": "dcbe1701-1bcb-432e-f827-095385bdad80"
   },
   "outputs": [],
   "source": [
    "plot(hybrid_train_losses, normal_train_losses, hybrid_train_accs, normal_train_accs, hybrid_train_aucs, normal_train_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965
    },
    "id": "joigUiQy-b67",
    "outputId": "c0e3f0e2-aa32-433d-89c0-27d55346781f"
   },
   "outputs": [],
   "source": [
    "plot(hybrid_val_losses, normal_val_losses, hybrid_val_accs, normal_val_accs, hybrid_val_aucs, normal_val_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HfcLNAxm-s5q",
    "outputId": "0951524b-0da6-40b9-d6bb-3de494671637"
   },
   "outputs": [],
   "source": [
    "test(model_hybrid, model_normal, test_loader, num_classes=num_classes)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6CjvHXlqfLwJ",
    "-QiXxOvofMEL",
    "W6OWC_aDfMW0"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
