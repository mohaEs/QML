{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i0eTf0VqdT9"
   },
   "source": [
    "### Installing and Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12160,
     "status": "ok",
     "timestamp": 1740720131938,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "D-MaCMIv5mjj",
    "outputId": "bbe421fa-0702-4a01-ebd5-8d25aaa19b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pennylane-lightning\n",
      "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
      "Collecting pennylane-lightning-gpu\n",
      "  Downloading PennyLane_Lightning_GPU-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
      "Collecting rustworkx>=0.14.0 (from pennylane)\n",
      "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
      "Collecting tomlkit (from pennylane)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting appdirs (from pennylane)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting autoray>=0.6.11 (from pennylane)\n",
      "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.12.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
      "Collecting diastatic-malt (from pennylane)\n",
      "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning)\n",
      "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting custatevec-cu12 (from pennylane-lightning-gpu)\n",
      "  Downloading custatevec_cu12-1.7.0-py3-none-manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning-gpu) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning-gpu) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning-gpu) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning-gpu) (12.5.82)\n",
      "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
      "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
      "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PennyLane_Lightning_GPU-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading custatevec_cu12-1.7.0-py3-none-manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: custatevec-cu12, appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane, pennylane-lightning-gpu\n",
      "Successfully installed appdirs-1.4.4 autoray-0.7.0 custatevec-cu12-1.7.0 diastatic-malt-2.15.2 pennylane-0.40.0 pennylane-lightning-0.40.0 pennylane-lightning-gpu-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n",
      "Requirement already satisfied: custatevec-cu12 in /usr/local/lib/python3.11/dist-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pennylane pennylane-lightning pennylane-lightning-gpu --upgrade\n",
    "\n",
    "!pip install custatevec-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x-nG8a2YzpO"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14114,
     "status": "ok",
     "timestamp": 1740720146084,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "RkRe0rr15zDM",
    "outputId": "4537dff1-37db-4a63-f545-39f60c3a4316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3_l3J878S7p"
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"../../QMLExperiments/Feature_Models/PAPILA_models/\"\n",
    "saved_Vectors_dir = \"../../Data/Vectors/PAPILA\"\n",
    "fundus_dir = \"../../Data/PAPILA\"\n",
    "dataset = \"PAPILA\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.makedirs(MODEL_SAVE_PATH)\n",
    "if not os.path.exists(saved_Vectors_dir):\n",
    "    os.makedirs(saved_Vectors_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ax6Hd54zWc_"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#from google.colab import drive\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import random\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXDdT8ey89hi"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir('/content/drive/MyDrive/H')\n",
    "#from RETFound_MAE import models_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmImen2IqETn"
   },
   "source": [
    "Feature Extraction with RETFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpDBh6JAnnyN"
   },
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "import models_vit\n",
    "def prepare_model(chkpt_dir, arch='vit_large_patch16'):\n",
    "    # build model\n",
    "    model = models_vit.__dict__[arch](\n",
    "        img_size=224,\n",
    "        num_classes=5,\n",
    "        drop_path_rate=0,\n",
    "        global_pool=True,\n",
    "    )\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu', weights_only=False)\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model):\n",
    "    x = torch.tensor(img)\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    latent = model.forward_features(x.float())\n",
    "    latent = torch.squeeze(latent)\n",
    "\n",
    "    return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29478,
     "status": "ok",
     "timestamp": 1740637157894,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "R-7lf-J7oOpo",
    "outputId": "aa16c0d0-e52d-4ded-f665-9bdccae7602f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-50c8a56d6e66>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(chkpt_dir, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# download pre-trained RETFound\n",
    "\n",
    "chkpt_dir = '../../RETFound/RETFound_cfp_weights.pth'\n",
    "model_ = prepare_model(chkpt_dir, 'vit_large_patch16')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_.to(device)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlCrIko2oRDf"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def feature_extract(data_path, model_, saved_Vectors_dir, dataset):\n",
    "    model_.eval()\n",
    "\n",
    "    feature_dicts = {\n",
    "        'train': {'names': [], 'features': [], 'labels': []},\n",
    "        'val': {'names': [], 'features': [], 'labels': []},\n",
    "        'test': {'names': [], 'features': [], 'labels': []}\n",
    "    }\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(data_path, split)\n",
    "\n",
    "        for class_name in tqdm(os.listdir(split_path)):\n",
    "            class_folder = os.path.join(split_path, class_name)\n",
    "\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                img_path = os.path.join(class_folder, img_name)\n",
    "\n",
    "                img = Image.open(img_path).resize((224, 224))\n",
    "                img_array = np.array(img) / 255.0\n",
    "                img_normalized = (img_array - imagenet_mean) / imagenet_std\n",
    "\n",
    "                x = torch.tensor(img_normalized)\n",
    "                x = x.unsqueeze(dim=0)\n",
    "                x = torch.einsum('nhwc->nchw', x)\n",
    "                x = x.to(device, non_blocking=True)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    latent = model_.forward_features(x.float())\n",
    "                    latent = torch.squeeze(latent)\n",
    "\n",
    "                feature_dicts[split]['names'].append(img_name)\n",
    "                feature_dicts[split]['features'].append(latent.detach().cpu().numpy())\n",
    "                feature_dicts[split]['labels'].append(class_name)\n",
    "\n",
    "    pickle.dump(feature_dicts['train'], open(os.path.join(saved_Vectors_dir,dataset+'_train.pkl'), 'wb'))\n",
    "    pickle.dump(feature_dicts['val'], open(os.path.join(saved_Vectors_dir,dataset+'_val.pkl'), 'wb'))\n",
    "    pickle.dump(feature_dicts['test'], open(os.path.join(saved_Vectors_dir,dataset+'_test.pkl'), 'wb'))\n",
    "\n",
    "    print(\"Feature extraction completed.\")\n",
    "    return feature_dicts\n",
    "\n",
    "def load_features(pkl_path='Feature_latent_multiclass.pkl'):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGvw-3FiDt4C"
   },
   "outputs": [],
   "source": [
    "feature_extract(fundus_dir, model_, saved_Vectors_dir, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcD00-I2gMzA"
   },
   "outputs": [],
   "source": [
    "num_qubits = 4\n",
    "batch_size = 4\n",
    "device = qml.device(\"default.qubit\", wires=num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2QD5NWXUV0y"
   },
   "outputs": [],
   "source": [
    "def load_and_shuffle_data(saved_Vectors_dir, dataset, seed=42, num_qubits=4):\n",
    "    with open(os.path.join(saved_Vectors_dir, dataset+'_train.pkl'), 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(os.path.join(saved_Vectors_dir,dataset+'_val.pkl'), 'rb') as f:\n",
    "        val_data = pickle.load(f)\n",
    "    with open(os.path.join(saved_Vectors_dir,dataset+'_test.pkl'), 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "\n",
    "    train_features = np.array(train_data['features'])\n",
    "    val_features = np.array(val_data['features'])\n",
    "    test_features = np.array(test_data['features'])\n",
    "\n",
    "    train_labels = np.array(train_data['labels'])\n",
    "    val_labels = np.array(val_data['labels'])\n",
    "    test_labels = np.array(test_data['labels'])\n",
    "\n",
    "    train_features, train_labels = shuffle(train_features, train_labels, random_state=seed)\n",
    "    val_features, val_labels = shuffle(val_features, val_labels, random_state=seed)\n",
    "    test_features, test_labels = shuffle(test_features, test_labels, random_state=seed)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(np.concatenate([train_labels, val_labels, test_labels]))\n",
    "\n",
    "    train_labels_encoded = label_encoder.transform(train_labels)\n",
    "    val_labels_encoded = label_encoder.transform(val_labels)\n",
    "    test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "    pca = PCA(n_components=num_qubits)\n",
    "    pca.fit(train_features)\n",
    "\n",
    "    train_features_reduced = pca.transform(train_features)\n",
    "    val_features_reduced = pca.transform(val_features)\n",
    "    test_features_reduced = pca.transform(test_features)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features_reduced)\n",
    "\n",
    "    train_features_scaled = scaler.transform(train_features_reduced)\n",
    "    val_features_scaled = scaler.transform(val_features_reduced)\n",
    "    test_features_scaled = scaler.transform(test_features_reduced)\n",
    "\n",
    "    return (train_features_scaled, train_labels_encoded,\n",
    "            val_features_scaled, val_labels_encoded,\n",
    "            test_features_scaled, test_labels_encoded,\n",
    "            label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF1roJmFWJB6"
   },
   "outputs": [],
   "source": [
    "def run_experiment(saved_Vectors_dir, dataset, model_func, num_qubits=4, seed=42, output_dir=MODEL_SAVE_PATH):\n",
    "    model_name = model_func.__name__.replace(\"run_\", \"\")\n",
    "    is_quantum = model_name.startswith(\"q\")\n",
    "    print(f\"Running {model_name.upper()} experiment on {dataset} dataset\")\n",
    "\n",
    "    print(f\"Loading and preprocessing data with seed {seed}...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, class_names = load_and_shuffle_data(saved_Vectors_dir, dataset,\n",
    "        seed=seed, num_qubits=num_qubits)\n",
    "\n",
    "    print(f\"Training and evaluating {model_name.upper()}...\")\n",
    "    if is_quantum:\n",
    "        model_result = model_func(X_train, y_train, X_val, y_val, X_test, y_test, num_qubits=num_qubits)\n",
    "    else:\n",
    "        model_result = model_func(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    result = {\n",
    "        'model': model_name,\n",
    "        'dataset': dataset,\n",
    "        'seed': seed,\n",
    "        'class_names': class_names,\n",
    "        'y_test': y_test,\n",
    "        'is_quantum': is_quantum,\n",
    "        'num_qubits': num_qubits if is_quantum else None,\n",
    "        **model_result\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{model_name.upper()} Results:\")\n",
    "    print(\"  Validation Metrics:\")\n",
    "    print(f\"    Accuracy:  {model_result['val_accuracy']:.4f}\")\n",
    "    print(f\"    Precision: {model_result['val_precision']:.4f}\")\n",
    "    print(f\"    Recall:    {model_result['val_recall']:.4f}\")\n",
    "    print(f\"    F1 Score:  {model_result['val_f1']:.4f}\")\n",
    "    print(\"  Test Metrics:\")\n",
    "    print(f\"    Accuracy:  {model_result['accuracy']:.4f}\")\n",
    "    print(f\"    Precision: {model_result['precision']:.4f}\")\n",
    "    print(f\"    Recall:    {model_result['recall']:.4f}\")\n",
    "    print(f\"    F1 Score:  {model_result['f1']:.4f}\")\n",
    "\n",
    "    output_file = os.path.join(output_dir, f'{model_name}_{dataset}_results.pkl')\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4uahmxSWwh6"
   },
   "outputs": [],
   "source": [
    "def run_qsvm(X_train, y_train, X_val, y_val, X_test, y_test, num_qubits=4):\n",
    "    dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def qksvm_kernel_cirq(a, b):\n",
    "        qml.AngleEmbedding(a, wires=range(num_qubits))\n",
    "        qml.adjoint(qml.AngleEmbedding(b, wires=range(num_qubits)))\n",
    "        return qml.probs(wires=range(num_qubits))\n",
    "\n",
    "    def quantum_kernel_pca(A, B):\n",
    "        return np.array([[qksvm_kernel_cirq(a, b)[0] for b in B] for a in A])\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', probability=True)\n",
    "\n",
    "    kernel_train = quantum_kernel_pca(X_train, X_train)\n",
    "    kernel_val = quantum_kernel_pca(X_train, X_val)\n",
    "    kernel_test = quantum_kernel_pca(X_train, X_test)\n",
    "\n",
    "    svm.fit(kernel_train, y_train)\n",
    "\n",
    "    val_pred = svm.predict(kernel_val.T)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    val_precision = precision_score(y_val, val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "\n",
    "    y_pred = svm.predict(kernel_test.T)\n",
    "    y_prob = svm.predict_proba(kernel_test.T)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VP9S8cLWulp"
   },
   "outputs": [],
   "source": [
    "def run_svm(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    print(\"Training SVM...\")\n",
    "    svm = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Computing validation predictions...\")\n",
    "    val_pred = svm.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    val_precision = precision_score(y_val, val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "\n",
    "    print(\"Computing test predictions...\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    y_prob = svm.predict_proba(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1n-VykYvW9cD"
   },
   "outputs": [],
   "source": [
    "def quantum_feature_map(x, num_qubits=4):\n",
    "    device = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "    @qml.qnode(device)\n",
    "    def feature_map_circuit():\n",
    "        for i in range(min(len(x), num_qubits)):\n",
    "            qml.RX(x[i], wires=i)\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(min(len(x), num_qubits))]\n",
    "\n",
    "    return feature_map_circuit()\n",
    "\n",
    "def qknn_fit(X_train, y_train, k=5, num_qubits=4):\n",
    "    quantum_X_train = np.array([quantum_feature_map(x, num_qubits) for x in X_train])\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(quantum_X_train, y_train)\n",
    "\n",
    "    return knn\n",
    "\n",
    "def qknn_predict(knn, X_test, num_qubits=4):\n",
    "    quantum_X_test = np.array([quantum_feature_map(x, num_qubits) for x in X_test])\n",
    "\n",
    "    return knn.predict(quantum_X_test)\n",
    "\n",
    "def qknn_predict_proba(knn, X_test, num_qubits=4):\n",
    "    quantum_X_test = np.array([quantum_feature_map(x, num_qubits) for x in X_test])\n",
    "\n",
    "    return knn.predict_proba(quantum_X_test)\n",
    "\n",
    "def run_qknn(X_train, y_train, X_val, y_val, X_test, y_test, num_qubits=4):\n",
    "    print(\"Training Quantum KNN...\")\n",
    "    knn = qknn_fit(X_train, y_train, k=5, num_qubits=num_qubits)\n",
    "\n",
    "    print(\"Computing validation predictions...\")\n",
    "    val_pred = qknn_predict(knn, X_val, num_qubits)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    val_precision = precision_score(y_val, val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "\n",
    "    print(\"Computing test predictions...\")\n",
    "    y_pred = qknn_predict(knn, X_test, num_qubits)\n",
    "\n",
    "    y_prob = qknn_predict_proba(knn, X_test, num_qubits)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZpDCAmOWuFY"
   },
   "outputs": [],
   "source": [
    "def run_knn(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    val_pred = knn.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    val_precision = precision_score(y_val, val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_prob = knn.predict_proba(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316232,
     "status": "ok",
     "timestamp": 1740720600737,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "B2dfcOV6YiJn",
    "outputId": "adadae08-90f8-4ee3-8f45-b2db69c03053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running QSVM experiment on PAPILA dataset\n",
      "Loading and preprocessing data with seed 42...\n",
      "Training and evaluating QSVM...\n",
      "\n",
      "QSVM Results:\n",
      "  Validation Metrics:\n",
      "    Accuracy:  0.4557\n",
      "    Precision: 0.6844\n",
      "    Recall:    0.4557\n",
      "    F1 Score:  0.4936\n",
      "  Test Metrics:\n",
      "    Accuracy:  0.4796\n",
      "    Precision: 0.6059\n",
      "    Recall:    0.4796\n",
      "    F1 Score:  0.5132\n",
      "Results saved to /content/drive/MyDrive/H/qmlData/qsvm_PAPILA_results.pkl\n"
     ]
    }
   ],
   "source": [
    "qsvm_result = run_experiment(saved_Vectors_dir, dataset, run_qsvm, num_qubits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1740710857317,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "9J_tuge0YlTn",
    "outputId": "7a45a1f6-f5b3-4222-af62-f46c53a06cfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM experiment on PAPILA dataset\n",
      "Loading and preprocessing data with seed 42...\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "Computing validation predictions...\n",
      "Computing test predictions...\n",
      "\n",
      "SVM Results:\n",
      "  Validation Metrics:\n",
      "    Accuracy:  0.4430\n",
      "    Precision: 0.6530\n",
      "    Recall:    0.4430\n",
      "    F1 Score:  0.4845\n",
      "  Test Metrics:\n",
      "    Accuracy:  0.5000\n",
      "    Precision: 0.6521\n",
      "    Recall:    0.5000\n",
      "    F1 Score:  0.5323\n",
      "Results saved to /content/drive/MyDrive/H/qmlData/svm_PAPILA_results.pkl\n"
     ]
    }
   ],
   "source": [
    "svm_result = run_experiment(saved_Vectors_dir, dataset, run_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1740710865509,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "ot4vPyHFXdTD",
    "outputId": "d368118b-6be9-4d4b-b6ec-18faebe0c781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN experiment on PAPILA dataset\n",
      "Loading and preprocessing data with seed 42...\n",
      "Training and evaluating KNN...\n",
      "\n",
      "KNN Results:\n",
      "  Validation Metrics:\n",
      "    Accuracy:  0.6203\n",
      "    Precision: 0.4854\n",
      "    Recall:    0.6203\n",
      "    F1 Score:  0.5446\n",
      "  Test Metrics:\n",
      "    Accuracy:  0.6837\n",
      "    Precision: 0.6713\n",
      "    Recall:    0.6837\n",
      "    F1 Score:  0.6489\n",
      "Results saved to /content/drive/MyDrive/H/qmlData/knn_PAPILA_results.pkl\n"
     ]
    }
   ],
   "source": [
    "knn_result = run_experiment(saved_Vectors_dir, dataset,run_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1740710867176,
     "user": {
      "displayName": "Zayan Hasan",
      "userId": "03259132731488643797"
     },
     "user_tz": 300
    },
    "id": "R1RQzDdyW-lQ",
    "outputId": "719fdca0-dd17-4ed2-e4e8-3f2208c1dede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running QKNN experiment on PAPILA dataset\n",
      "Loading and preprocessing data with seed 42...\n",
      "Training and evaluating QKNN...\n",
      "Training Quantum KNN...\n",
      "Computing validation predictions...\n",
      "Computing test predictions...\n",
      "\n",
      "QKNN Results:\n",
      "  Validation Metrics:\n",
      "    Accuracy:  0.6456\n",
      "    Precision: 0.4648\n",
      "    Recall:    0.6456\n",
      "    F1 Score:  0.5405\n",
      "  Test Metrics:\n",
      "    Accuracy:  0.6327\n",
      "    Precision: 0.4882\n",
      "    Recall:    0.6327\n",
      "    F1 Score:  0.5457\n",
      "Results saved to /content/drive/MyDrive/H/qmlData/qknn_PAPILA_results.pkl\n"
     ]
    }
   ],
   "source": [
    "qknn_result = run_experiment(saved_Vectors_dir, dataset, run_qknn, num_qubits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPUdtRjIW-qt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1VJanlhQiebO0C2sxA639KPo-1mqoK9E3",
     "timestamp": 1740710531913
    },
    {
     "file_id": "1ClpVakCGdCiu9V0x-BJ1zKJUoMiJY_pf",
     "timestamp": 1740710311219
    },
    {
     "file_id": "199MIiaTbxX2X98saW72DLJmCiAkvq3o7",
     "timestamp": 1740625982371
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
